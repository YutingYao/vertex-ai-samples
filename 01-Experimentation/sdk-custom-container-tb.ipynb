{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Training Job with Custom Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-workshop-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and test a training container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "MODEL_GARDEN_VERSION = '2.5.0'\n",
    "TRAIN_IMAGE = f'gcr.io/{PROJECT_ID}/model_garden'\n",
    "TF_TEXT='2.5.0'\n",
    "\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "\n",
    "RUN pip install tf-models-official=={MODEL_GARDEN_VERSION} tensorflow-text=={TF_TEXT}\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY nlp-trainer /trainer\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"-c\", \"print('Hello')\"]\n",
    "'''\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  353.8kB\n",
      "Step 1/6 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-5\n",
      " ---> 950969e5619c\n",
      "Step 2/6 : RUN pip install tf-models-official==2.5.0 tensorflow-text==2.5.0\n",
      " ---> Using cache\n",
      " ---> 8b4eaa89170c\n",
      "Step 3/6 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 6ee5de13c4a8\n",
      "Step 4/6 : COPY nlp-trainer /trainer\n",
      " ---> 5781c222eded\n",
      "Step 5/6 : ENTRYPOINT [\"python\"]\n",
      " ---> Running in 531968473baa\n",
      "Removing intermediate container 531968473baa\n",
      " ---> 12d7ec3c8fb7\n",
      "Step 6/6 : CMD [\"-c\", \"print('Hello')\"]\n",
      " ---> Running in e4bfca7d27ac\n",
      "Removing intermediate container e4bfca7d27ac\n",
      " ---> ba0eda1c5e0d\n",
      "Successfully built ba0eda1c5e0d\n",
      "Successfully tagged gcr.io/jk-mlops-dev/model_garden:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t {TRAIN_IMAGE} ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the container to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/model_garden]\n",
      "\n",
      "\u001b[1Bf56f092a: Preparing \n",
      "\u001b[1B12432222: Preparing \n",
      "\u001b[1B464d3f17: Preparing \n",
      "\u001b[1Bdaea14d2: Preparing \n",
      "\u001b[1Bb28de254: Preparing \n",
      "\u001b[1B52e30556: Preparing \n",
      "\u001b[1Bfc085027: Preparing \n",
      "\u001b[1B7d90a58d: Preparing \n",
      "\u001b[1B285b3362: Preparing \n",
      "\u001b[1B0730cb59: Preparing \n",
      "\u001b[1B18de1f93: Preparing \n",
      "\u001b[1Bd1dfb5d0: Preparing \n",
      "\u001b[1B686f5924: Preparing \n",
      "\u001b[1B5de2196f: Preparing \n",
      "\u001b[1B383a0e80: Preparing \n",
      "\u001b[1Beaf882b2: Preparing \n",
      "\u001b[1B2519572d: Preparing \n",
      "\u001b[1Bfbfba824: Preparing \n",
      "\u001b[1Ba8806df6: Preparing \n",
      "\u001b[1B2a1c8291: Preparing \n",
      "\u001b[1Bb49af22b: Preparing \n",
      "\u001b[1Bb363f69f: Preparing \n",
      "\u001b[1B0a9a6a11: Preparing \n",
      "\u001b[1B7e8b38e6: Preparing \n",
      "\u001b[1B8f196cf4: Preparing \n",
      "\u001b[1B01dbc7de: Preparing \n",
      "\u001b[1B31d2d72b: Preparing \n",
      "\u001b[1Ba966f459: Preparing \n",
      "\u001b[1Bb9e63cdf: Preparing \n",
      "\u001b[1B49f5bf51: Preparing \n",
      "\u001b[1Baa2fa9fe: Preparing \n",
      "\u001b[23B730cb59: Waiting g \n",
      "\u001b[1Bdd81f9fa: Preparing \n",
      "\u001b[33B2432222: Pushed   210.8MB/208.2MBg-platform-release/tf2-gpu.2-5 \u001b[33A\u001b[2K\u001b[31A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[29A\u001b[2K\u001b[28A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[26A\u001b[2K\u001b[25A\u001b[2K\u001b[33A\u001b[2K\u001b[24A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[23A\u001b[2K\u001b[33A\u001b[2K\u001b[22A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[19A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[16A\u001b[2K\u001b[33A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2K\u001b[33A\u001b[2Klatest: digest: sha256:d7a346385b3007fe92c81157ee3206bcbb9c4b3ca81d413c2d04b20d427bf01e size: 7461\n"
     ]
    }
   ],
   "source": [
    "! docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Vertext Training jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_worker_pool_specs(\n",
    "    image_uri,\n",
    "    args,\n",
    "    cmd, \n",
    "    replica_count=1,\n",
    "    machine_type='n1-standard-4',\n",
    "    accelerator_count=0,\n",
    "    accelerator_type='ACCELERATOR_TYPE_UNSPECIFIED'):\n",
    "\n",
    "    if accelerator_count > 0:\n",
    "        machine_spec = {\n",
    "            'machine_type': machine_type,\n",
    "            'accelerator_type': accelerator_type,\n",
    "            'accelerator_count': accelerator_count,\n",
    "        }\n",
    "    else:\n",
    "        machine_spec = {\n",
    "            'machine_type': machine_type\n",
    "        }\n",
    "    \n",
    "    container_spec = {\n",
    "        'image_uri': image_uri,\n",
    "        'args': args,\n",
    "        'command': cmd,\n",
    "    }\n",
    "    \n",
    "    chief_spec = {\n",
    "        'replica_count': 1,\n",
    "        'machine_spec': machine_spec,\n",
    "        'container_spec': container_spec\n",
    "    }\n",
    "\n",
    "    worker_pool_specs = [chief_spec]\n",
    "    if replica_count > 1:\n",
    "        workers_spec = {\n",
    "            'replica_count': replica_count - 1,\n",
    "            'machine_spec': machine_spec,\n",
    "            'container_spec': container_spec\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "    \n",
    "    return worker_pool_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'args': ['--experiment=bert/sentence_prediction',\n",
      "                              '--mode=train_and_eval',\n",
      "                              '--model_dir=gs://jk-vertex-demos/jobs/JOB_20210602_003422/model',\n",
      "                              '--config_file=trainer/glue_mnli_matched.yaml',\n",
      "                              '--tfhub_cache_dir=gs://jk-vertex-demos/jobs/tfhub-cache',\n",
      "                              '--params_override=task.train_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record,task.validation_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record,task.train_data.global_batch_size=32,task.validation_data.global_batch_size=32,task.hub_module_url=https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4,runtime.num_gpus=1,runtime.distribution_strategy=multi_worker_mirrored,runtime.all_reduce_alg=nccl'],\n",
      "                     'command': ['python', 'trainer/train.py'],\n",
      "                     'image_uri': 'gcr.io/jk-mlops-dev/model_garden'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1},\n",
      " {'container_spec': {'args': ['--experiment=bert/sentence_prediction',\n",
      "                              '--mode=train_and_eval',\n",
      "                              '--model_dir=gs://jk-vertex-demos/jobs/JOB_20210602_003422/model',\n",
      "                              '--config_file=trainer/glue_mnli_matched.yaml',\n",
      "                              '--tfhub_cache_dir=gs://jk-vertex-demos/jobs/tfhub-cache',\n",
      "                              '--params_override=task.train_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record,task.validation_data.input_path=gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record,task.train_data.global_batch_size=32,task.validation_data.global_batch_size=32,task.hub_module_url=https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4,runtime.num_gpus=1,runtime.distribution_strategy=multi_worker_mirrored,runtime.all_reduce_alg=nccl'],\n",
      "                     'command': ['python', 'trainer/train.py'],\n",
      "                     'image_uri': 'gcr.io/jk-mlops-dev/model_garden'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_T4',\n",
      "                   'machine_type': 'n1-standard-8'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "MNLI_TRAIN_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_train.tf_record'\n",
    "MNLI_VALID_SPLIT = 'gs://jk-vertex-demos/datasets/MNLI/mnli_valid.tf_record'\n",
    "BERT_HUB_URL = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4'\n",
    "\n",
    "job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "output_dir = f'gs://jk-vertex-demos/jobs'\n",
    "model_dir = f'{output_dir}/{job_name}/model'\n",
    "tfhub_cache_dir = f'{output_dir}/tfhub-cache'\n",
    "config_file = 'trainer/glue_mnli_matched.yaml'\n",
    "mode = 'train_and_eval'\n",
    "experiment = 'bert/sentence_prediction'\n",
    "\n",
    "machine_type = 'n1-standard-8'\n",
    "accelerator_count = 1\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "strategy = 'multi_worker_mirrored'\n",
    "\n",
    "replica_count = 2\n",
    "global_batch_size = 32\n",
    "\n",
    "params_override = [\n",
    "    'task.train_data.input_path=' + MNLI_TRAIN_SPLIT,\n",
    "    'task.validation_data.input_path=' + MNLI_VALID_SPLIT,\n",
    "    'task.train_data.global_batch_size=' + str(global_batch_size),\n",
    "    'task.validation_data.global_batch_size=' + str(global_batch_size),\n",
    "    'task.hub_module_url=' + BERT_HUB_URL,\n",
    "    'runtime.num_gpus=' + str(accelerator_count),\n",
    "    'runtime.distribution_strategy=' + strategy,\n",
    "    'runtime.all_reduce_alg=' + 'nccl',\n",
    "]\n",
    "\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"trainer/train.py\"\n",
    "]\n",
    "args = [\n",
    "    '--experiment=' + experiment,\n",
    "    '--mode=' + mode,\n",
    "    '--model_dir=' + model_dir,\n",
    "    '--config_file=' + config_file,\n",
    "    '--tfhub_cache_dir=' + tfhub_cache_dir,\n",
    "    '--params_override=' + ','.join(params_override),\n",
    "]\n",
    "\n",
    "worker_pool_specs = prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE,\n",
    "    args=args,\n",
    "    cmd=cmd,\n",
    "    replica_count=replica_count,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    accelerator_type=accelerator_type\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(pp.pformat(worker_pool_specs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/4909490941833773056\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/4909490941833773056')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4909490941833773056?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/4909490941833773056 current state:\n",
      "JobState.JOB_STATE_QUEUED\n"
     ]
    }
   ],
   "source": [
    "display_name = job_name\n",
    "\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=display_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    ")\n",
    "\n",
    "job.run(sync=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
