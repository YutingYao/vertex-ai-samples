{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefd15b9",
   "metadata": {},
   "source": [
    "# Custom Training Job with Tensorboard Monitoring\n",
    "\n",
    "This notebook demonstrates how to submit a custom Vertex training job and monitor it using Vertex TensorBoard. \n",
    "\n",
    "## Scenario\n",
    "\n",
    "The training scenario is fine-tuning BERT on the [GLUE COLA](https://nyu-mll.github.io/CoLA/) dataset. \n",
    "\n",
    "## Notes\n",
    "\n",
    "- The training regimen utilizes  [TensorFlow NLP Modelling Toolkit](https://github.com/tensorflow/models/tree/master/official/nlp)\n",
    "- Due to a complexity of the ML task, the custom training job is configured to use a multi-gpu training node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14d826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model\n",
    "import tensorflow_addons as tfa\n",
    "from official.nlp import optimization\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d24e5",
   "metadata": {},
   "source": [
    "## Evironment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d419d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-west1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-staging' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5246e1",
   "metadata": {},
   "source": [
    "## Configure data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6134d",
   "metadata": {},
   "source": [
    "### Make BERT data preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db16224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFHUB_HANDLE_PREPROCESS = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
    "    \"\"\"Returns a model mapping string features to BERT inputs.\"\"\"\n",
    "\n",
    "    input_segments = [\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
    "        for ft in sentence_features]\n",
    "\n",
    "    # Tokenize the text to word pieces.\n",
    "    bert_preprocess = hub.load(TFHUB_HANDLE_PREPROCESS)\n",
    "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
    "    segments = [tokenizer(s) for s in input_segments]\n",
    "\n",
    "    # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
    "    # are model-dependent, so this gets loaded from the SavedModel.\n",
    "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
    "                            arguments=dict(seq_length=seq_length),\n",
    "                            name='packer')\n",
    "    model_inputs = packer(segments)\n",
    "    return tf.keras.Model(input_segments, model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e4616",
   "metadata": {},
   "source": [
    "### Try BERT data preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15ebf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "Keys           :  ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape Word Ids :  (1, 128)\n",
      "Word Ids       :  tf.Tensor(\n",
      "[ 101 2070 6721 3231 6251  102 2178 6721 6251  102    0    0    0    0\n",
      "    0    0], shape=(16,), dtype=int32)\n",
      "Shape Mask     :  (1, 128)\n",
      "Input Mask     :  tf.Tensor([1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0], shape=(16,), dtype=int32)\n",
      "Shape Type Ids :  (1, 128)\n",
      "Type Ids       :  tf.Tensor([0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0], shape=(16,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "test_preprocess_model = make_bert_preprocess_model(['sentence1', 'sentence2'])\n",
    "test_text = [np.array(['some random test sentence']), \n",
    "             np.array(['another random sentence'])]\n",
    "text_preprocessed = test_preprocess_model(test_text)\n",
    "\n",
    "print('Keys           : ', list(text_preprocessed.keys()))\n",
    "print('Shape Word Ids : ', text_preprocessed['input_word_ids'].shape)\n",
    "print('Word Ids       : ', text_preprocessed['input_word_ids'][0, :16])\n",
    "print('Shape Mask     : ', text_preprocessed['input_mask'].shape)\n",
    "print('Input Mask     : ', text_preprocessed['input_mask'][0, :16])\n",
    "print('Shape Type Ids : ', text_preprocessed['input_type_ids'].shape)\n",
    "print('Type Ids       : ', text_preprocessed['input_type_ids'][0, :16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fff1a9",
   "metadata": {},
   "source": [
    "### Visualize BERT data preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07494fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(test_preprocess_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aefda7",
   "metadata": {},
   "source": [
    "## Configure the text classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa893e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFHUB_HANDLE_ENCODER = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "\n",
    "def build_classifier_model(num_classes, dropout_ratio):\n",
    "    \"\"\"Creates a text classification model based on BERT encoder.\"\"\"\n",
    "\n",
    "    inputs = dict(\n",
    "        input_word_ids=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
    "        input_mask=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
    "        input_type_ids=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    "\n",
    "    encoder = hub.KerasLayer(TFHUB_HANDLE_ENCODER, trainable=True, name='encoder')\n",
    "    net = encoder(inputs)['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(rate=dropout_ratio)(net)\n",
    "    net = tf.keras.layers.Dense(num_classes, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(inputs, net, name='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed63774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ratio = 0.1\n",
    "classes = 2\n",
    "\n",
    "classifier_model = build_classifier_model(classes, dropout_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d8e2ac",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ec0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_raw_result = classifier_model(text_preprocessed)\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fad6f",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efcabd",
   "metadata": {},
   "source": [
    "## Configure `tf.data` pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7431a46b",
   "metadata": {},
   "source": [
    "### Load the `glue/cola` dataset\n",
    "\n",
    "We will use  [TensorFlow Datasets](https://www.tensorflow.org/datasets). Since the `glue/cola` dataset is rather small we will load to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad835f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds_name = 'glue/cola' \n",
    "\n",
    "tfds_info = tfds.builder(tfds_name).info\n",
    "num_classes = tfds_info.features['label'].num_classes\n",
    "num_examples = tfds_info.splits.total_num_examples\n",
    "sentence_features = list(tfds_info.features.keys())\n",
    "available_splits = list(tfds_info.splits.keys())\n",
    "labels_names = tfds_info.features['label'].names\n",
    "\n",
    "print(f'Using {tfds_name} from TFDS')\n",
    "print(f'This dataset has {num_examples} examples')\n",
    "print(f'Number of classes: {num_classes}')\n",
    "print(f'Features {sentence_features}')\n",
    "print(f'Splits {available_splits}')\n",
    "print(f'Labels names {labels_names}')\n",
    "\n",
    "with tf.device('/job:localhost'):\n",
    "  # batch_size=-1 is a way to load the dataset into memory\n",
    "  in_memory_ds = tfds.load(tfds_name, batch_size=-1, shuffle_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda8385",
   "metadata": {},
   "source": [
    "### Show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds['train'])\n",
    "\n",
    "for row in sample_dataset.take(2):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1def48",
   "metadata": {},
   "source": [
    "### Create data ingestion pipelines.\n",
    "\n",
    "We will be training on a multi-gpu node using the `MirroredStrategy` distribution strategy. When using the `MirroredStrategy` each batch of the input is divided equally among the replicas. Typically, you would want to increase your batch size as you add more accelerators, so as to make effective use of the extra computing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_per_replica = 16\n",
    "global_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n",
    "features = ['sentence']\n",
    "\n",
    "\n",
    "def get_data_pipeline(in_memory_ds, info, split, batch_size,\n",
    "                           bert_preprocess_model):\n",
    "    is_training = split.startswith('train')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds[split])\n",
    "    num_examples = info.splits[split].num_examples\n",
    "\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(num_examples)\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda ex: (bert_preprocess_model(ex), ex['label']))\n",
    "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset, num_examples\n",
    "\n",
    "\n",
    "bert_preprocess_model = make_bert_preprocess_model(features)\n",
    "\n",
    "train_dataset, train_data_size = get_data_pipeline(\n",
    "      in_memory_ds, tfds_info, 'train', global_batch_size, bert_preprocess_model)\n",
    "\n",
    "validation_dataset, validation_data_size = get_data_pipeline(\n",
    "      in_memory_ds, tfds_info, 'validation', global_batch_size, bert_preprocess_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db48053",
   "metadata": {},
   "source": [
    "## Configure and test training\n",
    "\n",
    "### Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e8f7b",
   "metadata": {},
   "source": [
    "Fine-tuning follows the optimizer set-up from BERT pre-training (as in [Classify text with BERT](https://www.tensorflow.org/text/tutorials/classify_text_with_bert)): It uses the AdamW optimizer with a linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps (`num_warmup_steps`). In line with the BERT paper, the initial learning rate is smaller for fine-tuning (best of 5e-5, 3e-5, 2e-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75dfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "init_lr = 2e-5\n",
    "dropout_ratio = 0.1\n",
    "num_classes = 2\n",
    "# steps_per_epoch = train_data_size // global_batch_size\n",
    "steps_per_epoch = 50\n",
    "\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = num_train_steps // 10\n",
    "validation_steps = validation_data_size // global_batch_size\n",
    "\n",
    "with strategy.scope():\n",
    "    classifier_model = build_classifier_model(num_classes, dropout_ratio)\n",
    "    optimizer = optimization.create_optimizer(\n",
    "        init_lr=init_lr,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        optimizer_type='adamw')\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metrics = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        'accuracy', dtype=tf.float32)\n",
    "    \n",
    "classifier_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91346606",
   "metadata": {},
   "source": [
    "### Start a short training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c32379",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.fit(\n",
    "      x=train_dataset,\n",
    "      validation_data=validation_dataset,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      epochs=epochs,\n",
    "      validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5c8e7",
   "metadata": {},
   "source": [
    "## Run Vertex custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b456f9",
   "metadata": {},
   "source": [
    "### Intialize Vertex SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b56372",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fa68e",
   "metadata": {},
   "source": [
    "### Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63766da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'trainer'\n",
    "if tf.io.gfile.exists(folder):\n",
    "    tf.io.gfile.rmtree(folder)\n",
    "tf.io.gfile.mkdir(folder)\n",
    "file_path = os.path.join(folder, 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c948f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {file_path}\n",
    "\n",
    "\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "from official.nlp import optimization\n",
    "\n",
    "TFHUB_HANDLE_ENCODER = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
    "TFHUB_HANDLE_PREPROCESS = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "TFDS_NAME = 'glue/cola' \n",
    "NUM_CLASSES = 2\n",
    "SENTENCE_FEATURE = 'sentence'\n",
    "\n",
    "LOCAL_MODEL_DIR = '/tmp/saved_model'\n",
    "LOCAL_TB_DIR = '/tmp/logs'\n",
    "LOCAL_CHECKPOINT_DIR = '/tmp/checkpoints'\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('epochs', 2, 'Nubmer of epochs')\n",
    "flags.DEFINE_integer('per_replica_batch_size', 16, 'Per replica batch size')\n",
    "flags.DEFINE_float('init_lr', 2e-5, 'Initial learning rate')\n",
    "flags.DEFINE_float('dropout_ratio', 0.1, 'Dropout ratio')\n",
    "\n",
    "\n",
    "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
    "    \"\"\"Returns a model mapping string features to BERT inputs.\"\"\"\n",
    "\n",
    "    input_segments = [\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
    "        for ft in sentence_features]\n",
    "\n",
    "    # Tokenize the text to word pieces.\n",
    "    bert_preprocess = hub.load(TFHUB_HANDLE_PREPROCESS)\n",
    "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
    "    segments = [tokenizer(s) for s in input_segments]\n",
    "\n",
    "    # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
    "    # are model-dependent, so this gets loaded from the SavedModel.\n",
    "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
    "                            arguments=dict(seq_length=seq_length),\n",
    "                            name='packer')\n",
    "    model_inputs = packer(segments)\n",
    "    return tf.keras.Model(input_segments, model_inputs)\n",
    "\n",
    "\n",
    "def build_classifier_model(num_classes, dropout_ratio):\n",
    "    \"\"\"Creates a text classification model based on BERT encoder.\"\"\"\n",
    "\n",
    "    inputs = dict(\n",
    "        input_word_ids=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
    "        input_mask=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
    "        input_type_ids=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
    "    )\n",
    "\n",
    "    encoder = hub.KerasLayer(TFHUB_HANDLE_ENCODER, trainable=True, name='encoder')\n",
    "    net = encoder(inputs)['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(rate=dropout_ratio)(net)\n",
    "    net = tf.keras.layers.Dense(num_classes, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(inputs, net, name='prediction')\n",
    "\n",
    "\n",
    "def get_data_pipeline(in_memory_ds, info, split, \n",
    "                      batch_size,  bert_preprocess_model):\n",
    "    \"\"\"Creates a sentence preprocessing pipeline.\"\"\"\n",
    "    \n",
    "    is_training = split.startswith('train')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds[split])\n",
    "    num_examples = info.splits[split].num_examples\n",
    "\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(num_examples)\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda ex: (bert_preprocess_model(ex), ex['label']))\n",
    "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset, num_examples\n",
    "\n",
    "\n",
    "def set_job_dirs():\n",
    "    \"\"\"Sets job directories based on env variables set by Vertex AI.\"\"\"\n",
    "    \n",
    "    model_dir = os.getenv('AIP_MODEL_DIR', LOCAL_MODEL_DIR)\n",
    "    tb_dir = os.getenv('AIP_TENSORBOARD_LOG_DIR', LOCAL_TB_DIR)\n",
    "    checkpoint_dir = os.getenv('AIP_CHECKPOINT_DIR', LOCAL_CHECKPOINT_DIR)\n",
    "    \n",
    "    return model_dir, tb_dir, checkpoint_dir\n",
    "    \n",
    "\n",
    "def main(argv):\n",
    "    \"\"\"Starts a training run.\"\"\"\n",
    "    \n",
    "    del argv\n",
    "    logging.info('Setting up training.')\n",
    "    logging.info('   epochs: {}'.format(FLAGS.epochs))\n",
    "    logging.info('   per_replica_batch_size: {}'.format(FLAGS.per_replica_batch_size))\n",
    "    logging.info('   init_lr: {}'.format(FLAGS.init_lr))\n",
    "    logging.info('   dropout_ratio: {}'.format(FLAGS.dropout_ratio))\n",
    "\n",
    "    # Set distribution strategy\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    global_batch_size = (strategy.num_replicas_in_sync *\n",
    "                         FLAGS.per_replica_batch_size)\n",
    "    \n",
    "    # Configure input data pipelines\n",
    "    tfds_info = tfds.builder(TFDS_NAME).info\n",
    "    num_classes = tfds_info.features['label'].num_classes\n",
    "    num_examples = tfds_info.splits.total_num_examples\n",
    "    available_splits = list(tfds_info.splits.keys())\n",
    "    labels_names = tfds_info.features['label'].names\n",
    "    \n",
    "    with tf.device('/job:localhost'):\n",
    "        in_memory_ds = tfds.load(TFDS_NAME, batch_size=-1, shuffle_files=True)\n",
    "        \n",
    "    bert_preprocess_model = make_bert_preprocess_model([SENTENCE_FEATURE])\n",
    "\n",
    "    train_dataset, train_data_size = get_data_pipeline(\n",
    "        in_memory_ds, tfds_info, 'train', global_batch_size, bert_preprocess_model)\n",
    "\n",
    "    validation_dataset, validation_data_size = get_data_pipeline(\n",
    "        in_memory_ds, tfds_info, 'validation', global_batch_size, bert_preprocess_model)\n",
    "    \n",
    "    # Configure the model\n",
    "    steps_per_epoch = train_data_size // global_batch_size\n",
    "    num_train_steps = steps_per_epoch * FLAGS.epochs\n",
    "    num_warmup_steps = num_train_steps // 10\n",
    "    validation_steps = validation_data_size // global_batch_size\n",
    "    \n",
    "    with strategy.scope():\n",
    "        classifier_model = build_classifier_model(NUM_CLASSES, FLAGS.dropout_ratio)\n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=FLAGS.init_lr,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            optimizer_type='adamw')\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        metrics = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "            'accuracy', dtype=tf.float32)\n",
    "    \n",
    "    classifier_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n",
    "    \n",
    "    model_dir, tb_dir, checkpoint_dir = set_job_dirs()\n",
    "\n",
    "    # Configure Keras callbacks\n",
    "    callbacks = [tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=checkpoint_dir)]\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=tb_dir, update_freq='batch'))\n",
    "    \n",
    "    logging.info('Starting training ...')\n",
    "    classifier_model.fit(\n",
    "        x=train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=FLAGS.epochs,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks)\n",
    "        \n",
    "    # Save trained model\n",
    "    logging.info('Training completed. Saving the trained model to: {}'.format(model_dir))\n",
    "    classifier_model.save(model_dir)  \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff4387",
   "metadata": {},
   "source": [
    "### Configure and submit Vertex job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{GCS_BUCKET}/jobs/{job_name}'\n",
    "requirements = ['tf-models-official==2.5.0', 'tensorflow-text==2.5.0']\n",
    "args = ['--epochs=3', '--per_replica_batch_size=16']\n",
    "machine_type = 'n1-standard-8',\n",
    "accelerator_type = 'nvidia-tesla-t4'\n",
    "accelerator_count = 2\n",
    "\n",
    "job = vertex_ai.CustomJob.from_local_script(\n",
    "    display_name=job_name,\n",
    "    script_path='trainer/train.py',\n",
    "    container_uri=BASE_IMAGE,\n",
    "    requirements=requirements,\n",
    "    args=args\n",
    ")\n",
    "\n",
    "job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af42af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106af664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
